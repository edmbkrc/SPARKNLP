{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6xOGNGdY2oc",
        "outputId": "4ed53a65-abb0-44c1-a837-b405ab033405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spark-nlp\n",
            "  Downloading spark_nlp-5.4.2-py2.py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m964.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Downloading spark_nlp-5.4.2-py2.py3-none-any.whl (579 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m579.5/579.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=a443eacf04f3d2da170ca4a1d98f596bff72bda34c67d5ef982f99eb6a6397bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: spark-nlp, pyspark\n",
            "Successfully installed pyspark-3.5.2 spark-nlp-5.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "spark = sparknlp.start()\n",
        "spark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "BtuIcJSfZCSp",
        "outputId": "800f93cd-d28e-4ce2-8cdf-8b1f9a943b44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ffa92f55870>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://70c978e0029e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CaseSensitive\n",
        "Whether to do a case-sensitive comparison over the stop words (Default: false)"
      ],
      "metadata": {
        "id": "Z6DYR4wNZQWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documenter = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"document\")\n",
        "\n",
        "sentencer = SentenceDetector()\\\n",
        ".setInputCols([\"document\"])\\\n",
        ".setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        ".setInputCols([\"sentence\"])\\\n",
        ".setOutputCol(\"token\")\n",
        "\n",
        "stop_words = StopWordsCleaner()\\\n",
        ".setInputCols([\"token\"])\\\n",
        ".setOutputCol(\"cleanTokens\")\\\n",
        ".setCaseSensitive(False)\n",
        "\n",
        "pipeline = Pipeline(stages=[documenter, sentencer, tokenizer, stop_words])\n",
        "\n",
        "data = spark.createDataFrame([[\"Tom is a nice man. He lives in Kashmir.\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "result.select(\"cleanTokens.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfkmCdg9ZHtA",
        "outputId": "f6823615-c03a-469a-a164-dc72b8a5d438"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------+\n",
            "|result                                |\n",
            "+--------------------------------------+\n",
            "|[Tom, nice, man, ., lives, Kashmir, .]|\n",
            "+--------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As nothing specified, by default CaseSensitive = False . So if any stopword from the default (Stop words from MLlib) is present, it is removed. In this case, words like: \"is\", \"a\", \"He\", \"in\" were removed."
      ],
      "metadata": {
        "id": "Hl5bT16MaZAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  CaseSensitive = True"
      ],
      "metadata": {
        "id": "s2GrwI45aaYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documenter = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"document\")\n",
        "\n",
        "sentencer = SentenceDetector()\\\n",
        ".setInputCols([\"document\"])\\\n",
        ".setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        ".setInputCols([\"sentence\"])\\\n",
        ".setOutputCol(\"token\")\n",
        "\n",
        "stop_words = StopWordsCleaner()\\\n",
        ".setInputCols([\"token\"])\\\n",
        ".setOutputCol(\"cleanTokens\")\\\n",
        ".setCaseSensitive(True)\n",
        "\n",
        "pipeline = Pipeline(stages=[documenter, sentencer, tokenizer, stop_words])\n",
        "\n",
        "data = spark.createDataFrame([[\"Tom is a nice man. He lives in Kashmir.\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "result.select(\"cleanTokens.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IGx0SllaO8-",
        "outputId": "49a9f28a-e542-4060-c50b-bee7b9783c53"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+\n",
            "|result                                    |\n",
            "+------------------------------------------+\n",
            "|[Tom, nice, man, ., He, lives, Kashmir, .]|\n",
            "+------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because of CaseSensitive = True, the word \"He\" was not considered a stopword because all stopwords in MLlibs StopWordsRemover are specified in lowercase."
      ],
      "metadata": {
        "id": "nHNTDXQgaom-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stopwords from MLlibs StopWordsRemover"
      ],
      "metadata": {
        "id": "55TdrHEYaumR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words.getStopWords()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb8laPXEagAX",
        "outputId": "99ab4c5d-fb8b-44ab-de4e-e8822410bbce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " 'should',\n",
              " 'now',\n",
              " \"i'll\",\n",
              " \"you'll\",\n",
              " \"he'll\",\n",
              " \"she'll\",\n",
              " \"we'll\",\n",
              " \"they'll\",\n",
              " \"i'd\",\n",
              " \"you'd\",\n",
              " \"he'd\",\n",
              " \"she'd\",\n",
              " \"we'd\",\n",
              " \"they'd\",\n",
              " \"i'm\",\n",
              " \"you're\",\n",
              " \"he's\",\n",
              " \"she's\",\n",
              " \"it's\",\n",
              " \"we're\",\n",
              " \"they're\",\n",
              " \"i've\",\n",
              " \"we've\",\n",
              " \"you've\",\n",
              " \"they've\",\n",
              " \"isn't\",\n",
              " \"aren't\",\n",
              " \"wasn't\",\n",
              " \"weren't\",\n",
              " \"haven't\",\n",
              " \"hasn't\",\n",
              " \"hadn't\",\n",
              " \"don't\",\n",
              " \"doesn't\",\n",
              " \"didn't\",\n",
              " \"won't\",\n",
              " \"wouldn't\",\n",
              " \"shan't\",\n",
              " \"shouldn't\",\n",
              " \"mustn't\",\n",
              " \"can't\",\n",
              " \"couldn't\",\n",
              " 'cannot',\n",
              " 'could',\n",
              " \"here's\",\n",
              " \"how's\",\n",
              " \"let's\",\n",
              " 'ought',\n",
              " \"that's\",\n",
              " \"there's\",\n",
              " \"what's\",\n",
              " \"when's\",\n",
              " \"where's\",\n",
              " \"who's\",\n",
              " \"why's\",\n",
              " 'would']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## StopWords: as an array of strings from a text file or manually."
      ],
      "metadata": {
        "id": "ITBp3RoYa6Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = StopWordsCleaner()\\\n",
        ".setInputCols([\"token\"])\\\n",
        ".setOutputCol(\"cleanTokens\")\\\n",
        ".setCaseSensitive(False)\\\n",
        ".setStopWords([\"Tom\", \"a\"])\n",
        "\n",
        "pipeline = Pipeline(stages=[documenter, sentencer, tokenizer, stop_words])\n",
        "\n",
        "data = spark.createDataFrame([[\"Tom is a nice man. He lives in Kashmir.\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "result.select(\"cleanTokens.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT3duFWta1D_",
        "outputId": "f009f2a9-043d-4077-9c30-eacddaef0ac0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------+\n",
            "|result                                       |\n",
            "+---------------------------------------------+\n",
            "|[is, nice, man, ., He, lives, in, Kashmir, .]|\n",
            "+---------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Token positions are preserved."
      ],
      "metadata": {
        "id": "8moWKr3Ibl-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = StopWordsCleaner()\\\n",
        ".setInputCols([\"token\"])\\\n",
        ".setOutputCol(\"cleanTokens\")\\\n",
        ".setCaseSensitive(False)\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[documenter, sentencer, tokenizer, stop_words])\n",
        "\n",
        "data = spark.createDataFrame([[\"Tom is a nice man. He lives in Kashmir.\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n"
      ],
      "metadata": {
        "id": "lw3m070HbPry"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"token.result\",\"token.begin\",\"token.end\").withColumnRenamed(\"result\",\"Tokens\").show(truncate=False)\n",
        "result.select(\"cleanTokens.result\",\"cleanTokens.begin\",\"cleanTokens.end\").withColumnRenamed(\"result\",\"Clean Tokens\").show(truncate=False)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYyJaU1jbzSE",
        "outputId": "ee27ac28-6e8f-489a-c9db-84a61222b573"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------+----------------------------------------+-----------------------------------------+\n",
            "|Tokens                                               |begin                                   |end                                      |\n",
            "+-----------------------------------------------------+----------------------------------------+-----------------------------------------+\n",
            "|[Tom, is, a, nice, man, ., He, lives, in, Kashmir, .]|[0, 4, 7, 9, 14, 17, 19, 22, 28, 31, 38]|[2, 5, 7, 12, 16, 17, 20, 26, 29, 37, 38]|\n",
            "+-----------------------------------------------------+----------------------------------------+-----------------------------------------+\n",
            "\n",
            "+--------------------------------------+--------------------------+---------------------------+\n",
            "|Clean Tokens                          |begin                     |end                        |\n",
            "+--------------------------------------+--------------------------+---------------------------+\n",
            "|[Tom, nice, man, ., lives, Kashmir, .]|[0, 9, 14, 17, 22, 31, 38]|[2, 12, 16, 17, 26, 37, 38]|\n",
            "+--------------------------------------+--------------------------+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## StopWordsCleaner Pre-trained Models"
      ],
      "metadata": {
        "id": "y4aeVddvcKV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documenter = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"document\")\n",
        "\n",
        "sentencer = SentenceDetector()\\\n",
        ".setInputCols([\"document\"])\\\n",
        ".setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        ".setInputCols([\"sentence\"])\\\n",
        ".setOutputCol(\"token\")\n",
        "\n",
        "stop_words = StopWordsCleaner.pretrained(\"stopwords_iso\", \"en\")\\\n",
        ".setInputCols([\"token\"])\\\n",
        ".setOutputCol(\"cleanTokens\")\\\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[documenter, sentencer, tokenizer, stop_words])\n",
        "\n",
        "data = spark.createDataFrame([[\"You are not better than me\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "result.select(\"cleanTokens.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mYGKWtab9I9",
        "outputId": "7aa58f33-0a91-4eb0-d13a-452bfa912f6c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopwords_iso download started this may take some time.\n",
            "Approximate size to download 2.1 KB\n",
            "[OK!]\n",
            "+--------+\n",
            "|result  |\n",
            "+--------+\n",
            "|[better]|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pretrained model (\"stopwords_iso\", \"en\") stopwords\n",
        "stop_words.getStopWords()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQzK9PTccn3A",
        "outputId": "73012ff1-677c-49f1-aea8-4d36001e69e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'across',\n",
              " 'after',\n",
              " 'afterwards',\n",
              " 'again',\n",
              " 'against',\n",
              " 'all',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'along',\n",
              " 'already',\n",
              " 'also',\n",
              " 'although',\n",
              " 'always',\n",
              " 'am',\n",
              " 'among',\n",
              " 'amongst',\n",
              " 'amount',\n",
              " 'an',\n",
              " 'and',\n",
              " 'another',\n",
              " 'any',\n",
              " 'anyhow',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'anyway',\n",
              " 'anywhere',\n",
              " 'are',\n",
              " 'around',\n",
              " 'as',\n",
              " 'at',\n",
              " 'back',\n",
              " 'be',\n",
              " 'became',\n",
              " 'because',\n",
              " 'become',\n",
              " 'becomes',\n",
              " 'becoming',\n",
              " 'been',\n",
              " 'before',\n",
              " 'beforehand',\n",
              " 'behind',\n",
              " 'being',\n",
              " 'below',\n",
              " 'beside',\n",
              " 'besides',\n",
              " 'between',\n",
              " 'beyond',\n",
              " 'both',\n",
              " 'bottom',\n",
              " 'but',\n",
              " 'by',\n",
              " 'call',\n",
              " 'can',\n",
              " 'cannot',\n",
              " 'ca',\n",
              " 'could',\n",
              " 'did',\n",
              " 'do',\n",
              " 'does',\n",
              " 'doing',\n",
              " 'done',\n",
              " 'down',\n",
              " 'due',\n",
              " 'during',\n",
              " 'each',\n",
              " 'eight',\n",
              " 'either',\n",
              " 'eleven',\n",
              " 'else',\n",
              " 'elsewhere',\n",
              " 'empty',\n",
              " 'enough',\n",
              " 'even',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'everyone',\n",
              " 'everything',\n",
              " 'everywhere',\n",
              " 'except',\n",
              " 'few',\n",
              " 'fifteen',\n",
              " 'fifty',\n",
              " 'first',\n",
              " 'five',\n",
              " 'for',\n",
              " 'former',\n",
              " 'formerly',\n",
              " 'forty',\n",
              " 'four',\n",
              " 'from',\n",
              " 'front',\n",
              " 'full',\n",
              " 'further',\n",
              " 'get',\n",
              " 'give',\n",
              " 'go',\n",
              " 'had',\n",
              " 'has',\n",
              " 'have',\n",
              " 'he',\n",
              " 'hence',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hereafter',\n",
              " 'hereby',\n",
              " 'herein',\n",
              " 'hereupon',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'however',\n",
              " 'hundred',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'indeed',\n",
              " 'into',\n",
              " 'is',\n",
              " 'it',\n",
              " 'its',\n",
              " 'itself',\n",
              " 'keep',\n",
              " 'last',\n",
              " 'latter',\n",
              " 'latterly',\n",
              " 'least',\n",
              " 'less',\n",
              " 'just',\n",
              " 'made',\n",
              " 'make',\n",
              " 'many',\n",
              " 'may',\n",
              " 'me',\n",
              " 'meanwhile',\n",
              " 'might',\n",
              " 'mine',\n",
              " 'more',\n",
              " 'moreover',\n",
              " 'most',\n",
              " 'mostly',\n",
              " 'move',\n",
              " 'much',\n",
              " 'must',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'name',\n",
              " 'namely',\n",
              " 'neither',\n",
              " 'never',\n",
              " 'nevertheless',\n",
              " 'next',\n",
              " 'nine',\n",
              " 'no',\n",
              " 'nobody',\n",
              " 'none',\n",
              " 'noone',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'nothing',\n",
              " 'now',\n",
              " 'nowhere',\n",
              " 'of',\n",
              " 'off',\n",
              " 'often',\n",
              " 'on',\n",
              " 'once',\n",
              " 'one',\n",
              " 'only',\n",
              " 'onto',\n",
              " 'or',\n",
              " 'other',\n",
              " 'others',\n",
              " 'otherwise',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 'part',\n",
              " 'per',\n",
              " 'perhaps',\n",
              " 'please',\n",
              " 'put',\n",
              " 'quite',\n",
              " 'rather',\n",
              " 're',\n",
              " 'really',\n",
              " 'regarding',\n",
              " 'same',\n",
              " 'say',\n",
              " 'see',\n",
              " 'seem',\n",
              " 'seemed',\n",
              " 'seeming',\n",
              " 'seems',\n",
              " 'serious',\n",
              " 'several',\n",
              " 'she',\n",
              " 'should',\n",
              " 'show',\n",
              " 'side',\n",
              " 'since',\n",
              " 'six',\n",
              " 'sixty',\n",
              " 'so',\n",
              " 'some',\n",
              " 'somehow',\n",
              " 'someone',\n",
              " 'something',\n",
              " 'sometime',\n",
              " 'sometimes',\n",
              " 'somewhere',\n",
              " 'still',\n",
              " 'such',\n",
              " 'take',\n",
              " 'ten',\n",
              " 'than',\n",
              " 'that',\n",
              " 'the',\n",
              " 'their',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'thence',\n",
              " 'there',\n",
              " 'thereafter',\n",
              " 'thereby',\n",
              " 'therefore',\n",
              " 'therein',\n",
              " 'thereupon',\n",
              " 'these',\n",
              " 'they',\n",
              " 'third',\n",
              " 'this',\n",
              " 'those',\n",
              " 'though',\n",
              " 'three',\n",
              " 'through',\n",
              " 'throughout',\n",
              " 'thru',\n",
              " 'thus',\n",
              " 'to',\n",
              " 'together',\n",
              " 'too',\n",
              " 'top',\n",
              " 'toward',\n",
              " 'towards',\n",
              " 'twelve',\n",
              " 'twenty',\n",
              " 'two',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 'unless',\n",
              " 'upon',\n",
              " 'us',\n",
              " 'used',\n",
              " 'using',\n",
              " 'various',\n",
              " 'very',\n",
              " 'very',\n",
              " 'via',\n",
              " 'was',\n",
              " 'we',\n",
              " 'well',\n",
              " 'were',\n",
              " 'what',\n",
              " 'whatever',\n",
              " 'when',\n",
              " 'whence',\n",
              " 'whenever',\n",
              " 'where',\n",
              " 'whereafter',\n",
              " 'whereas',\n",
              " 'whereby',\n",
              " 'wherein',\n",
              " 'whereupon',\n",
              " 'wherever',\n",
              " 'whether',\n",
              " 'which',\n",
              " 'while',\n",
              " 'whither',\n",
              " 'who',\n",
              " 'whoever',\n",
              " 'whole',\n",
              " 'whom',\n",
              " 'whose',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'within',\n",
              " 'without',\n",
              " 'would',\n",
              " 'yet',\n",
              " 'you',\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## other languages stopwords"
      ],
      "metadata": {
        "id": "DvukuekWc_-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documenter = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"document\")\n",
        "\n",
        "sentencer = SentenceDetector()\\\n",
        ".setInputCols([\"document\"])\\\n",
        ".setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        ".setInputCols([\"sentence\"])\\\n",
        ".setOutputCol(\"token\")\n",
        "\n",
        "stop_words = StopWordsCleaner.pretrained(\"stopwords_iso\", \"tr\")\\\n",
        ".setInputCols([\"token\"])\\\n",
        ".setOutputCol(\"cleanTokens\")\\\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[documenter, sentencer, tokenizer, stop_words])\n",
        "\n",
        "data = spark.createDataFrame([[\"Dinlenmemek üzere yola çıkanlar asla yorulmazlar. İyi daha iyinin düşmanıdır.\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "result.select(\"cleanTokens.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-gkLO32cyRK",
        "outputId": "eb9b98f4-7157-4bb1-c796-c02011e050eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopwords_iso download started this may take some time.\n",
            "Approximate size to download 3.1 KB\n",
            "[OK!]\n",
            "+-------------------------------------------------------------------------------+\n",
            "|result                                                                         |\n",
            "+-------------------------------------------------------------------------------+\n",
            "|[Dinlenmemek, yola, çıkanlar, asla, yorulmazlar, ., İyi, iyinin, düşmanıdır, .]|\n",
            "+-------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words.getStopWords()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUeqcrP_dZkz",
        "outputId": "3414b5f6-49fc-46bc-e7fc-e51602355149"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['acaba',\n",
              " 'acep',\n",
              " 'adamakıllı',\n",
              " 'adeta',\n",
              " 'ait',\n",
              " 'ama',\n",
              " 'amma',\n",
              " 'anca',\n",
              " 'ancak',\n",
              " 'arada',\n",
              " 'artık',\n",
              " 'aslında',\n",
              " 'aynen',\n",
              " 'ayrıca',\n",
              " 'az',\n",
              " 'açıkça',\n",
              " 'açıkçası',\n",
              " 'bana',\n",
              " 'bari',\n",
              " 'bazen',\n",
              " 'bazı',\n",
              " 'bazısı',\n",
              " 'bazısına',\n",
              " 'bazısında',\n",
              " 'bazısından',\n",
              " 'bazısını',\n",
              " 'bazısının',\n",
              " 'başkası',\n",
              " 'başkasına',\n",
              " 'başkasında',\n",
              " 'başkasından',\n",
              " 'başkasını',\n",
              " 'başkasının',\n",
              " 'başka',\n",
              " 'belki',\n",
              " 'ben',\n",
              " 'bende',\n",
              " 'benden',\n",
              " 'beni',\n",
              " 'benim',\n",
              " 'beri',\n",
              " 'beriki',\n",
              " 'berikinin',\n",
              " 'berikiyi',\n",
              " 'berisi',\n",
              " 'bilcümle',\n",
              " 'bile',\n",
              " 'binaen',\n",
              " 'binaenaleyh',\n",
              " 'biraz',\n",
              " 'birazdan',\n",
              " 'birbiri',\n",
              " 'birbirine',\n",
              " 'birbirini',\n",
              " 'birbirinin',\n",
              " 'birbirinde',\n",
              " 'birbirinden',\n",
              " 'birden',\n",
              " 'birdenbire',\n",
              " 'biri',\n",
              " 'birine',\n",
              " 'birini',\n",
              " 'birinin',\n",
              " 'birinde',\n",
              " 'birinden',\n",
              " 'birice',\n",
              " 'birileri',\n",
              " 'birilerinde',\n",
              " 'birilerinden',\n",
              " 'birilerine',\n",
              " 'birilerini',\n",
              " 'birilerinin',\n",
              " 'birisi',\n",
              " 'birisine',\n",
              " 'birisini',\n",
              " 'birisinin',\n",
              " 'birisinde',\n",
              " 'birisinden',\n",
              " 'birkaç',\n",
              " 'birkaçı',\n",
              " 'birkaçına',\n",
              " 'birkaçını',\n",
              " 'birkaçının',\n",
              " 'birkaçında',\n",
              " 'birkaçından',\n",
              " 'birkez',\n",
              " 'birlikte',\n",
              " 'birçok',\n",
              " 'birçoğu',\n",
              " 'birçoğuna',\n",
              " 'birçoğunda',\n",
              " 'birçoğundan',\n",
              " 'birçoğunu',\n",
              " 'birçoğunun',\n",
              " 'birşey',\n",
              " 'birşeyi',\n",
              " 'bitevi',\n",
              " 'biteviye',\n",
              " 'bittabi',\n",
              " 'biz',\n",
              " 'bizatihi',\n",
              " 'bizce',\n",
              " 'bizcileyin',\n",
              " 'bizden',\n",
              " 'bize',\n",
              " 'bizi',\n",
              " 'bizim',\n",
              " 'bizimki',\n",
              " 'bizzat',\n",
              " 'boşuna',\n",
              " 'bu',\n",
              " 'buna',\n",
              " 'bunda',\n",
              " 'bundan',\n",
              " 'bunlar',\n",
              " 'bunları',\n",
              " 'bunların',\n",
              " 'bunu',\n",
              " 'bunun',\n",
              " 'buracıkta',\n",
              " 'burada',\n",
              " 'buradan',\n",
              " 'burası',\n",
              " 'burasına',\n",
              " 'burasını',\n",
              " 'burasının',\n",
              " 'burasında',\n",
              " 'burasından',\n",
              " 'böyle',\n",
              " 'böylece',\n",
              " 'böylecene',\n",
              " 'böylelikle',\n",
              " 'böylemesine',\n",
              " 'böylesine',\n",
              " 'büsbütün',\n",
              " 'bütün',\n",
              " 'cuk',\n",
              " 'cümlesi',\n",
              " 'cümlesine',\n",
              " 'cümlesini',\n",
              " 'cümlesinin',\n",
              " 'cümlesinden',\n",
              " 'cümlemize',\n",
              " 'cümlemizi',\n",
              " 'cümlemizden',\n",
              " 'çabuk',\n",
              " 'çabukça',\n",
              " 'çeşitli',\n",
              " 'çok',\n",
              " 'çokları',\n",
              " 'çoklarınca',\n",
              " 'çokluk',\n",
              " 'çoklukla',\n",
              " 'çokça',\n",
              " 'çoğu',\n",
              " 'çoğun',\n",
              " 'çoğunca',\n",
              " 'çoğunda',\n",
              " 'çoğundan',\n",
              " 'çoğunlukla',\n",
              " 'çoğunu',\n",
              " 'çoğunun',\n",
              " 'çünkü',\n",
              " 'da',\n",
              " 'daha',\n",
              " 'dahası',\n",
              " 'dahi',\n",
              " 'dahil',\n",
              " 'dahilen',\n",
              " 'daima',\n",
              " 'dair',\n",
              " 'dayanarak',\n",
              " 'de',\n",
              " 'defa',\n",
              " 'dek',\n",
              " 'demin',\n",
              " 'demincek',\n",
              " 'deminden',\n",
              " 'denli',\n",
              " 'derakap',\n",
              " 'derhal',\n",
              " 'derken',\n",
              " 'değil',\n",
              " 'değin',\n",
              " 'diye',\n",
              " 'diğer',\n",
              " 'diğeri',\n",
              " 'diğerine',\n",
              " 'diğerini',\n",
              " 'diğerinden',\n",
              " 'dolayı',\n",
              " 'dolayısıyla',\n",
              " 'doğru',\n",
              " 'edecek',\n",
              " 'eden',\n",
              " 'ederek',\n",
              " 'edilecek',\n",
              " 'ediliyor',\n",
              " 'edilmesi',\n",
              " 'ediyor',\n",
              " 'elbet',\n",
              " 'elbette',\n",
              " 'emme',\n",
              " 'en',\n",
              " 'enikonu',\n",
              " 'epey',\n",
              " 'epeyce',\n",
              " 'epeyi',\n",
              " 'esasen',\n",
              " 'esnasında',\n",
              " 'etmesi',\n",
              " 'etraflı',\n",
              " 'etraflıca',\n",
              " 'etti',\n",
              " 'ettiği',\n",
              " 'ettiğini',\n",
              " 'evleviyetle',\n",
              " 'evvel',\n",
              " 'evvela',\n",
              " 'evvelce',\n",
              " 'evvelden',\n",
              " 'evvelemirde',\n",
              " 'evveli',\n",
              " 'eğer',\n",
              " 'fakat',\n",
              " 'filanca',\n",
              " 'filancanın',\n",
              " 'gah',\n",
              " 'gayet',\n",
              " 'gayetle',\n",
              " 'gayri',\n",
              " 'gayrı',\n",
              " 'gelgelelim',\n",
              " 'gene',\n",
              " 'gerek',\n",
              " 'gerçi',\n",
              " 'geçende',\n",
              " 'geçenlerde',\n",
              " 'gibi',\n",
              " 'gibilerden',\n",
              " 'gibisinden',\n",
              " 'gine',\n",
              " 'göre',\n",
              " 'gırla',\n",
              " 'hakeza',\n",
              " 'halbuki',\n",
              " 'halen',\n",
              " 'halihazırda',\n",
              " 'haliyle',\n",
              " 'handiyse',\n",
              " 'hangi',\n",
              " 'hangisi',\n",
              " 'hangisine',\n",
              " 'hangisine',\n",
              " 'hangisinde',\n",
              " 'hangisinden',\n",
              " 'hani',\n",
              " 'hariç',\n",
              " 'hasebiyle',\n",
              " 'hasılı',\n",
              " 'hatta',\n",
              " 'hele',\n",
              " 'hem',\n",
              " 'henüz',\n",
              " 'hep',\n",
              " 'hepsi',\n",
              " 'hepsini',\n",
              " 'hepsinin',\n",
              " 'hepsinde',\n",
              " 'hepsinden',\n",
              " 'her',\n",
              " 'herhangi',\n",
              " 'herkes',\n",
              " 'herkesi',\n",
              " 'herkesin',\n",
              " 'herkesten',\n",
              " 'hiç',\n",
              " 'hiçbir',\n",
              " 'hiçbiri',\n",
              " 'hiçbirine',\n",
              " 'hiçbirini',\n",
              " 'hiçbirinin',\n",
              " 'hiçbirinde',\n",
              " 'hiçbirinden',\n",
              " 'hoş',\n",
              " 'hulasaten',\n",
              " 'iken',\n",
              " 'ila',\n",
              " 'ile',\n",
              " 'ilen',\n",
              " 'ilgili',\n",
              " 'ilk',\n",
              " 'illa',\n",
              " 'illaki',\n",
              " 'imdi',\n",
              " 'indinde',\n",
              " 'inen',\n",
              " 'insermi',\n",
              " 'ise',\n",
              " 'ister',\n",
              " 'itibaren',\n",
              " 'itibariyle',\n",
              " 'itibarıyla',\n",
              " 'iyi',\n",
              " 'iyice',\n",
              " 'iyicene',\n",
              " 'için',\n",
              " 'iş',\n",
              " 'işte',\n",
              " 'kadar',\n",
              " 'kaffesi',\n",
              " 'kah',\n",
              " 'kala',\n",
              " 'kanımca',\n",
              " 'karşın',\n",
              " 'kaynak',\n",
              " 'kaçı',\n",
              " 'kaçına',\n",
              " 'kaçında',\n",
              " 'kaçından',\n",
              " 'kaçını',\n",
              " 'kaçının',\n",
              " 'kelli',\n",
              " 'kendi',\n",
              " 'kendilerinde',\n",
              " 'kendilerinden',\n",
              " 'kendilerine',\n",
              " 'kendilerini',\n",
              " 'kendilerinin',\n",
              " 'kendini',\n",
              " 'kendisi',\n",
              " 'kendisinde',\n",
              " 'kendisinden',\n",
              " 'kendisine',\n",
              " 'kendisini',\n",
              " 'kendisinin',\n",
              " 'kere',\n",
              " 'kez',\n",
              " 'keza',\n",
              " 'kezalik',\n",
              " 'keşke',\n",
              " 'ki',\n",
              " 'kim',\n",
              " 'kimden',\n",
              " 'kime',\n",
              " 'kimi',\n",
              " 'kiminin',\n",
              " 'kimisi',\n",
              " 'kimisinde',\n",
              " 'kimisinden',\n",
              " 'kimisine',\n",
              " 'kimisinin',\n",
              " 'kimse',\n",
              " 'kimsecik',\n",
              " 'kimsecikler',\n",
              " 'külliyen',\n",
              " 'kısaca',\n",
              " 'kısacası',\n",
              " 'lakin',\n",
              " 'leh',\n",
              " 'lütfen',\n",
              " 'maada',\n",
              " 'madem',\n",
              " 'mademki',\n",
              " 'mamafih',\n",
              " 'mebni',\n",
              " 'međer',\n",
              " 'meğer',\n",
              " 'meğerki',\n",
              " 'meğerse',\n",
              " 'mu',\n",
              " 'mü',\n",
              " 'mı',\n",
              " 'mi',\n",
              " 'nasıl',\n",
              " 'nasılsa',\n",
              " 'nazaran',\n",
              " 'naşi',\n",
              " 'ne',\n",
              " 'neden',\n",
              " 'nedeniyle',\n",
              " 'nedenle',\n",
              " 'nedenler',\n",
              " 'nedenlerden',\n",
              " 'nedense',\n",
              " 'nerde',\n",
              " 'nerden',\n",
              " 'nerdeyse',\n",
              " 'nere',\n",
              " 'nerede',\n",
              " 'nereden',\n",
              " 'neredeyse',\n",
              " 'neresi',\n",
              " 'nereye',\n",
              " 'netekim',\n",
              " 'neye',\n",
              " 'neyi',\n",
              " 'neyse',\n",
              " 'nice',\n",
              " 'nihayet',\n",
              " 'nihayetinde',\n",
              " 'nitekim',\n",
              " 'niye',\n",
              " 'niçin',\n",
              " 'o',\n",
              " 'olan',\n",
              " 'olarak',\n",
              " 'oldu',\n",
              " 'olduklarını',\n",
              " 'oldukça',\n",
              " 'olduğu',\n",
              " 'olduğunu',\n",
              " 'olmak',\n",
              " 'olması',\n",
              " 'olsa',\n",
              " 'olsun',\n",
              " 'olup',\n",
              " 'olur',\n",
              " 'olursa',\n",
              " 'oluyor',\n",
              " 'ona',\n",
              " 'onca',\n",
              " 'onculayın',\n",
              " 'onda',\n",
              " 'ondan',\n",
              " 'onlar',\n",
              " 'onlara',\n",
              " 'onlardan',\n",
              " 'onları',\n",
              " 'onların',\n",
              " 'onu',\n",
              " 'onun',\n",
              " 'ora',\n",
              " 'oracık',\n",
              " 'oracıkta',\n",
              " 'orada',\n",
              " 'oradan',\n",
              " 'oranca',\n",
              " 'oranla',\n",
              " 'oraya',\n",
              " 'oysa',\n",
              " 'oysaki',\n",
              " 'öbür',\n",
              " 'öbürkü',\n",
              " 'öbürü',\n",
              " 'öbüründe',\n",
              " 'öbüründen',\n",
              " 'öbürüne',\n",
              " 'öbürünü',\n",
              " 'önce',\n",
              " 'önceden',\n",
              " 'önceleri',\n",
              " 'öncelikle',\n",
              " 'öteki',\n",
              " 'ötekisi',\n",
              " 'öyle',\n",
              " 'öylece',\n",
              " 'öylelikle',\n",
              " 'öylemesine',\n",
              " 'öz',\n",
              " 'pek',\n",
              " 'pekala',\n",
              " 'peki',\n",
              " 'pekçe',\n",
              " 'peyderpey',\n",
              " 'rağmen',\n",
              " 'sadece',\n",
              " 'sahi',\n",
              " 'sahiden',\n",
              " 'sana',\n",
              " 'sanki',\n",
              " 'sen',\n",
              " 'senden',\n",
              " 'seni',\n",
              " 'senin',\n",
              " 'siz',\n",
              " 'sizden',\n",
              " 'sizi',\n",
              " 'sizin',\n",
              " 'sonra',\n",
              " 'sonradan',\n",
              " 'sonraları',\n",
              " 'sonunda',\n",
              " 'şayet',\n",
              " 'şey',\n",
              " 'şeyden',\n",
              " 'şeyi',\n",
              " 'şeyler',\n",
              " 'şu',\n",
              " 'şuna',\n",
              " 'şuncacık',\n",
              " 'şunda',\n",
              " 'şundan',\n",
              " 'şunlar',\n",
              " 'şunları',\n",
              " 'şunların',\n",
              " 'şunu',\n",
              " 'şunun',\n",
              " 'şura',\n",
              " 'şuracık',\n",
              " 'şuracıkta',\n",
              " 'şurası',\n",
              " 'şöyle',\n",
              " 'şimdi',\n",
              " 'tabii',\n",
              " 'tam',\n",
              " 'tamam',\n",
              " 'tamamen',\n",
              " 'tamamıyla',\n",
              " 'tarafından',\n",
              " 'tek',\n",
              " 'tüm',\n",
              " 'üzere',\n",
              " 'var',\n",
              " 'vardı',\n",
              " 'vasıtasıyla',\n",
              " 've',\n",
              " 'velev',\n",
              " 'velhasıl',\n",
              " 'velhasılıkelam',\n",
              " 'veya',\n",
              " 'veyahut',\n",
              " 'ya',\n",
              " 'yahut',\n",
              " 'yakinen',\n",
              " 'yakında',\n",
              " 'yakından',\n",
              " 'yakınlarda',\n",
              " 'yalnız',\n",
              " 'yalnızca',\n",
              " 'yani',\n",
              " 'yapacak',\n",
              " 'yapmak',\n",
              " 'yaptı',\n",
              " 'yaptıkları',\n",
              " 'yaptığı',\n",
              " 'yaptığını',\n",
              " 'yapılan',\n",
              " 'yapılması',\n",
              " 'yapıyor',\n",
              " 'yeniden',\n",
              " 'yenilerde',\n",
              " 'yerine',\n",
              " 'yine',\n",
              " 'yok',\n",
              " 'yoksa',\n",
              " 'yoluyla',\n",
              " 'yüzünden',\n",
              " 'zarfında',\n",
              " 'zaten',\n",
              " 'zati',\n",
              " 'zira']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zk4D_0pwdkSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}