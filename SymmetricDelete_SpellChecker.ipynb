{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c13EO-o7UZJt"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark==3.1.2  spark-nlp==4.2.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = sparknlp.start()\n"
      ],
      "metadata": {
        "id": "Ug_TmoUJUziB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        ".setInputCol(\"text\") \\\n",
        ".setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        ".setInputCols([\"document\"]) \\\n",
        ".setOutputCol(\"token\")\n",
        "\n",
        "# \"spellcheck_sd\" can be omitted, as it is the default value\n",
        "spellChecker = SymmetricDeleteModel.pretrained(\"spellcheck_sd\")\\\n",
        ".setInputCols([\"token\"]) \\\n",
        ".setOutputCol(\"spell\")\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "documentAssembler,\n",
        "tokenizer,\n",
        "spellChecker\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([[\"somtimes i wrrite wordz erong.\"]]).toDF(\"text\")\n",
        "result = pipeline.fit(data).transform(data)\n",
        "result.select(col('token.result').alias(\"before_spellchecker\"), col('spell.result').alias(\"after_spellchecker\")).show(truncate = False)"
      ],
      "metadata": {
        "id": "IlAb9agDU2pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a spellchecker using SymmetricDeleteApproach"
      ],
      "metadata": {
        "id": "4uUbjTv4Xl94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        ".setInputCol(\"text\") \\\n",
        ".setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        ".setInputCols([\"document\"]) \\\n",
        ".setOutputCol(\"token\")\n",
        "\n",
        "spellChecker = SymmetricDeleteApproach() \\\n",
        ".setInputCols([\"token\"]) \\\n",
        ".setOutputCol(\"spell\")\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "documentAssembler,\n",
        "tokenizer,\n",
        "spellChecker\n",
        "])\n",
        "\n",
        "training_df = spark.createDataFrame([[\"The dog and the cat play together.\"]]).to_DF(\"text\")\n",
        "\n",
        "spellcheck_model = pipeline.fit(training_df)\n",
        "\n",
        "text_df = spark.createDataFrame([[\"The dogh and th caat is eating\"]]).to_DF(\"text\")\n",
        "\n",
        "corrected_text = spellcheck_model.transform(text_df)\n",
        "corrected_text.select(col(\"token.result\").alias(\"before_spellchecker\"), col(\"spell.result\").alias(\"after_spellchecker\")).show(truncate=False)\n"
      ],
      "metadata": {
        "id": "sSbcM6nmXS5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setDictionary"
      ],
      "metadata": {
        "id": "aIddsyaiscA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "external_dict = '''\n",
        "dogs\n",
        "are\n",
        "'''\n",
        "with open('external_dict.txt', 'w') as f:\n",
        "  f.write(external_dict)\n",
        "\n",
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "spellChecker_1 = SymmetricDeleteApproach() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"spell_1\")\n",
        "\n",
        "spellChecker_2 = SymmetricDeleteApproach() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"spell_2\") \\\n",
        "    .setDictionary(\"external_dict.txt\")\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    spellChecker_1,\n",
        "    spellChecker_2\n",
        "])\n",
        "\n",
        "\n",
        "training_df = spark.createDataFrame([[\"The dog and the cat play together.\"]]).toDF(\"text\")\n",
        "\n",
        "spellcheck_model = pipeline.fit(training_df)\n",
        "\n",
        "text_df = spark.createDataFrame([[\"teh dogs aree eating.\"]]).toDF(\"text\")\n",
        "\n",
        "corrected_text = spellcheck_model.transform(text_df)\n",
        "\n",
        "corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell_1.result').alias(\"spellchecker_without_dict\"), col('spell_2.result').alias(\"spellchecker_with_dict\")).show(truncate = False)"
      ],
      "metadata": {
        "id": "LjviXO-1ZLU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setDupsLimit"
      ],
      "metadata": {
        "id": "uLSrkrFos6o4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "spellChecker_1 = SymmetricDeleteApproach() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"spell_1\") \\\n",
        "    .setDupsLimit(1)\n",
        "\n",
        "spellChecker_2 = SymmetricDeleteApproach() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"spell_2\") \\\n",
        "    .setDupsLimit(0)\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    spellChecker_1,\n",
        "    spellChecker_2\n",
        "])\n",
        "\n",
        "training_df = spark.createDataFrame([[\"it was a good day, and the dog played alone.\"]]).toDF(\"text\")\n",
        "\n",
        "spellcheck_model = pipeline.fit(training_df)\n",
        "\n",
        "text_df = spark.createDataFrame([[\"it was a goood dogg.\"]]).toDF(\"text\")\n",
        "\n",
        "corrected_text = spellcheck_model.transform(text_df)\n",
        "\n",
        "corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell_1.result').alias(\"dups_limit_1\"), col('spell_2.result').alias(\"dups_limit_0\")).show(truncate = False)"
      ],
      "metadata": {
        "id": "Qi63Uzs3szcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setFrequencyThreshold"
      ],
      "metadata": {
        "id": "hL2td3e0tHOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "spellChecker_1 = SymmetricDeleteApproach() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"spell_1\") \\\n",
        "    .setFrequencyThreshold(0)\n",
        "\n",
        "spellChecker_2 = SymmetricDeleteApproach() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"spell_2\") \\\n",
        "    .setFrequencyThreshold(2)\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    spellChecker_1,\n",
        "    spellChecker_2\n",
        "])\n",
        "\n",
        "training_df = spark.createDataFrame([[\"the dog and the cat play together.\"]]).toDF(\"text\")\n",
        "\n",
        "spellcheck_model = pipeline.fit(training_df)\n",
        "\n",
        "text_df = spark.createDataFrame([[\"teh dogh is eating.\"]]).toDF(\"text\")\n",
        "\n",
        "corrected_text = spellcheck_model.transform(text_df)\n",
        "\n",
        "corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell_1.result').alias(\"frequency_threshold_0\"), col('spell_2.result').alias(\"frequency_threshold_2\")).show(truncate = False)"
      ],
      "metadata": {
        "id": "IWWOwYuItIVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the spellchecker with frequencyThreshold = 2 did not correct the misspelled word \"dogh\", because the correct spelling of that word appears only once in the training data. In contrast to this, the word \"teh\" was corrected, because \"the\" appears at least twice in the training data."
      ],
      "metadata": {
        "id": "rjLw7j0dtbI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setMaxEditDistance"
      ],
      "metadata": {
        "id": "sYF3XJDitq75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "spellChecker_1 = SymmetricDeleteApproach() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"spell_1\") \\\n",
        "    .setMaxEditDistance(1)\n",
        "\n",
        "spellChecker_2 = SymmetricDeleteApproach() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"spell_2\") \\\n",
        "    .setMaxEditDistance(2)\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    spellChecker_1,\n",
        "    spellChecker_2\n",
        "])\n",
        "\n",
        "training_df = spark.createDataFrame([[\"the dog and the cat play together.\"]]).toDF(\"text\")\n",
        "\n",
        "spellcheck_model = pipeline.fit(training_df)\n",
        "\n",
        "text_df = spark.createDataFrame([[\"teh dogh is eating.\"]]).toDF(\"text\")\n",
        "\n",
        "corrected_text = spellcheck_model.transform(text_df)\n",
        "\n",
        "corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell_1.result').alias(\"max_edit_distance_1\"), col('spell_2.result').alias(\"max_edit_distance_2\")).show(truncate = False)"
      ],
      "metadata": {
        "id": "WQZhuwrvtboA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When maxEditDistance is 1, \"teh\" is not corrected to \"the\" because the amount of edits that are needed (2 letters) is higher than the maximum amount of edits that are allowed."
      ],
      "metadata": {
        "id": "lIHKzqd8t26h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-qKVcLaCt3dE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}