{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEev3CqEaz0i",
        "outputId": "9be525b7-d47a-44e2-8033-48be1414a07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spark-nlp\n",
            "  Downloading spark_nlp-5.5.0-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Downloading spark_nlp-5.5.0-py2.py3-none-any.whl (620 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.8/620.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=222142c64966f9a904c0087a1accd1ed3690977ea36e2d99bd9ca243d3e81d51\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: spark-nlp, pyspark\n",
            "Successfully installed pyspark-3.5.3 spark-nlp-5.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StringType, IntegerType\n",
        "\n",
        "spark = sparknlp.start()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "wIFRToINa-7L",
        "outputId": "bb48d456-6374-49be-9c48-419d37a70f88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7b4d7a2375e0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://89c57d323255:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['Peter Parker is a nice lad and lives in New York']\n",
        "\n",
        "df = spark.createDataFrame(text, StringType()).toDF('text')\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gqvYINVbgqB",
        "outputId": "9b4d45e3-f99b-446a-8c97-5509d5ac9d07"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------+\n",
            "|text                                            |\n",
            "+------------------------------------------------+\n",
            "|Peter Parker is a nice lad and lives in New York|\n",
            "+------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documenter = DocumentAssembler()\\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel.pretrained()\\\n",
        "    .setInputCols(['document', 'token'])\\\n",
        "    .setOutputCol('embeddings')\n",
        "\n",
        "ner_tagger = NerDLModel.pretrained(\"ner_dl\", \"en\")\\\n",
        "    .setInputCols(['document', 'token', 'embeddings'])\\\n",
        "    .setOutputCol('ner')\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "    .setInputCols(['document', 'token', 'ner'])\\\n",
        "    .setOutputCol('ner_chunk')\n",
        "\n",
        "chunk_tokenizer = ChunkTokenizer() \\\n",
        "    .setInputCols([\"ner_chunk\"]) \\\n",
        "    .setOutputCol(\"chunk_token\")\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    documenter,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    ner_tagger,\n",
        "    ner_converter,\n",
        "    chunk_tokenizer\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF0pJhkXb6ea",
        "outputId": "932b213a-2237-4623-8a1d-9d3b8b8e74d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "ner_dl download started this may take some time.\n",
            "Approximate size to download 13.6 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(df).transform(df)\n",
        "model.selectExpr(\"ner_chunk.result as ner_chunk\", \"chunk_token.result as chunk_token\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRj4H6neeuB-",
        "outputId": "2f383d8b-9679-470c-c1e2-6c78cba42562"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------+--------------------------+\n",
            "|ner_chunk               |chunk_token               |\n",
            "+------------------------+--------------------------+\n",
            "|[Peter Parker, New York]|[Peter, Parker, New, York]|\n",
            "+------------------------+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documenter = DocumentAssembler()\\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel.pretrained()\\\n",
        "    .setInputCols(['document', 'token'])\\\n",
        "    .setOutputCol('embeddings')\n",
        "\n",
        "ner_tagger = NerDLModel.pretrained(\"ner_dl\", \"en\")\\\n",
        "    .setInputCols(['document', 'token', 'embeddings'])\\\n",
        "    .setOutputCol('ner')\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "    .setInputCols(['document', 'token', 'ner'])\\\n",
        "    .setOutputCol('ner_chunk')\n",
        "\n",
        "chunk_tokenizer = ChunkTokenizer() \\\n",
        "    .setInputCols([\"ner_chunk\"]) \\\n",
        "    .setOutputCol(\"chunk_token\")\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    documenter,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    ner_tagger,\n",
        "    ner_converter,\n",
        "    chunk_tokenizer\n",
        "])\n",
        "\n",
        "text= [\"After spending several months studying abroad in Spain, John Wick returned home with a newfound appreciation for the Spanish language and culture.\",\n",
        "         \"Despite the fact that I had saved up 100.000 USD, I still found it difficult to afford a house in the city.\",\n",
        "         \"When I was a child, my grandparents would take me on long walks through the countryside, and those memories are still some of my most cherished.\",\n",
        "         \"After years of working in the corporate world, I decided to start my own business, and I've never looked back.\",\n",
        "         \"The ancient ruins we visited in Rome were so awe-inspiring that I found myself speechless.\",\n",
        "         \"Despite the fact that I had been practicing for months, my piano recital was a disaster, and I was humiliated.\",\n",
        "         \"When she traveled to Thailand, Mary was amazed by the beauty and serenity of the Buddhist temples.\",\n",
        "         \"My grandmother's estate, which had been passed down through several generations of our family, was the site of many cherished family gatherings.\",\n",
        "         \"When I was a student, I spent a semester studying abroad in France, and it was one of the most enriching experiences of my life.\",\n",
        "         \"After my grandfather passed away, my family and I spent weeks going through his belongings and reminiscing about his life.\",\n",
        "         \"The White House is located in Washington, D.C.\",\n",
        "         \"I need to exchange dollars for euros before I travel to Europe.\",\n",
        "         \"The exchange rate between the pound and the euro is favorable.\",\n",
        "         \"As a child, I used to spend my summers at my grandparents' farm, and those days are some of my most cherished memories.\",\n",
        "         \"After years of working for a multinational corporation, I decided to quit my job and travel the World.\",\n",
        "         \"My great-grandfather fought in World War II, and his stories about the war have been passed down through the generations of our family.\",\n",
        "         \"When I was in college, I spent a semester studying abroad in China, and it was an eye-opening experience.\",\n",
        "         \"My best friend and I have been planning a trip to South America for years, and we're finally going to make it happen this summer.\",\n",
        "         \"My parents own a small motel in a charming seaside town, and they've been running it for over 20 years.\",\n",
        "         \"Johnson and I decided to take a road trip across the United States during the summer after we graduated from college.\"]\n",
        "\n",
        "df = spark.createDataFrame(text, StringType()).toDF('text')\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNWB7dTfeZhY",
        "outputId": "85d09a41-822e-4fab-e651-6454b4fed2ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "ner_dl download started this may take some time.\n",
            "Approximate size to download 13.6 MB\n",
            "[OK!]\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|text                                                                                                                                              |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|After spending several months studying abroad in Spain, John Wick returned home with a newfound appreciation for the Spanish language and culture.|\n",
            "|Despite the fact that I had saved up 100.000 USD, I still found it difficult to afford a house in the city.                                       |\n",
            "|When I was a child, my grandparents would take me on long walks through the countryside, and those memories are still some of my most cherished.  |\n",
            "|After years of working in the corporate world, I decided to start my own business, and I've never looked back.                                    |\n",
            "|The ancient ruins we visited in Rome were so awe-inspiring that I found myself speechless.                                                        |\n",
            "|Despite the fact that I had been practicing for months, my piano recital was a disaster, and I was humiliated.                                    |\n",
            "|When she traveled to Thailand, Mary was amazed by the beauty and serenity of the Buddhist temples.                                                |\n",
            "|My grandmother's estate, which had been passed down through several generations of our family, was the site of many cherished family gatherings.  |\n",
            "|When I was a student, I spent a semester studying abroad in France, and it was one of the most enriching experiences of my life.                  |\n",
            "|After my grandfather passed away, my family and I spent weeks going through his belongings and reminiscing about his life.                        |\n",
            "|The White House is located in Washington, D.C.                                                                                                    |\n",
            "|I need to exchange dollars for euros before I travel to Europe.                                                                                   |\n",
            "|The exchange rate between the pound and the euro is favorable.                                                                                    |\n",
            "|As a child, I used to spend my summers at my grandparents' farm, and those days are some of my most cherished memories.                           |\n",
            "|After years of working for a multinational corporation, I decided to quit my job and travel the World.                                            |\n",
            "|My great-grandfather fought in World War II, and his stories about the war have been passed down through the generations of our family.           |\n",
            "|When I was in college, I spent a semester studying abroad in China, and it was an eye-opening experience.                                         |\n",
            "|My best friend and I have been planning a trip to South America for years, and we're finally going to make it happen this summer.                 |\n",
            "|My parents own a small motel in a charming seaside town, and they've been running it for over 20 years.                                           |\n",
            "|Johnson and I decided to take a road trip across the United States during the summer after we graduated from college.                             |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=[\n",
        "    documenter,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    ner_tagger,\n",
        "    ner_converter,\n",
        "    chunk_tokenizer\n",
        "])\n",
        "\n",
        "model = pipeline.fit(df).transform(df)\n",
        "model.selectExpr(\"embeddings.result as embeddings\", \"ner.result as ner\", \"ner_chunk.result as ner_chunk\", \"chunk_token.result as chunk_token\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0bGbQZFgFWS",
        "outputId": "75cc4234-9e70-4956-f890-c483559f724c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+------------------------------+-------------------------------+\n",
            "|embeddings                                                                                                                                                                       |ner                                                                                       |ner_chunk                     |chunk_token                    |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+------------------------------+-------------------------------+\n",
            "|[After, spending, several, months, studying, abroad, in, Spain, ,, John, Wick, returned, home, with, a, newfound, appreciation, for, the, Spanish, language, and, culture, .]    |[O, O, O, O, O, O, O, B-LOC, O, B-PER, I-PER, O, O, O, O, O, O, O, O, B-MISC, O, O, O, O] |[Spain, John Wick, Spanish]   |[Spain, John, Wick, Spanish]   |\n",
            "|[Despite, the, fact, that, I, had, saved, up, 100.000, USD, ,, I, still, found, it, difficult, to, afford, a, house, in, the, city, .]                                           |[O, O, O, O, O, O, O, O, O, B-MISC, O, O, O, O, O, O, O, O, O, O, O, O, O, O]             |[USD]                         |[USD]                          |\n",
            "|[When, I, was, a, child, ,, my, grandparents, would, take, me, on, long, walks, through, the, countryside, ,, and, those, memories, are, still, some, of, my, most, cherished, .]|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   |[]                            |[]                             |\n",
            "|[After, years, of, working, in, the, corporate, world, ,, I, decided, to, start, my, own, business, ,, and, I've, never, looked, back, .]                                        |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PER, O, O, O, O]                 |[I've]                        |[I've]                         |\n",
            "|[The, ancient, ruins, we, visited, in, Rome, were, so, awe-inspiring, that, I, found, myself, speechless, .]                                                                     |[O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O]                                      |[Rome]                        |[Rome]                         |\n",
            "|[Despite, the, fact, that, I, had, been, practicing, for, months, ,, my, piano, recital, was, a, disaster, ,, and, I, was, humiliated, .]                                        |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                     |[]                            |[]                             |\n",
            "|[When, she, traveled, to, Thailand, ,, Mary, was, amazed, by, the, beauty, and, serenity, of, the, Buddhist, temples, .]                                                         |[O, O, O, O, B-LOC, O, B-PER, O, O, O, O, O, O, O, O, O, B-MISC, O, O]                    |[Thailand, Mary, Buddhist]    |[Thailand, Mary, Buddhist]     |\n",
            "|[My, grandmother's, estate, ,, which, had, been, passed, down, through, several, generations, of, our, family, ,, was, the, site, of, many, cherished, family, gatherings, .]    |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]               |[]                            |[]                             |\n",
            "|[When, I, was, a, student, ,, I, spent, a, semester, studying, abroad, in, France, ,, and, it, was, one, of, the, most, enriching, experiences, of, my, life, .]                 |[O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  |[France]                      |[France]                       |\n",
            "|[After, my, grandfather, passed, away, ,, my, family, and, I, spent, weeks, going, through, his, belongings, and, reminiscing, about, his, life, .]                              |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                        |[]                            |[]                             |\n",
            "|[The, White, House, is, located, in, Washington, ,, D.C, .]                                                                                                                      |[O, B-LOC, I-LOC, O, O, O, B-LOC, O, B-LOC, O]                                            |[White House, Washington, D.C]|[White, House, Washington, D.C]|\n",
            "|[I, need, to, exchange, dollars, for, euros, before, I, travel, to, Europe, .]                                                                                                   |[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O]                                               |[Europe]                      |[Europe]                       |\n",
            "|[The, exchange, rate, between, the, pound, and, the, euro, is, favorable, .]                                                                                                     |[O, O, O, O, O, O, O, O, O, O, O, O]                                                      |[]                            |[]                             |\n",
            "|[As, a, child, ,, I, used, to, spend, my, summers, at, my, grandparents, ', farm, ,, and, those, days, are, some, of, my, most, cherished, memories, .]                          |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]         |[]                            |[]                             |\n",
            "|[After, years, of, working, for, a, multinational, corporation, ,, I, decided, to, quit, my, job, and, travel, the, World, .]                                                    |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-MISC, O]                         |[World]                       |[World]                        |\n",
            "|[My, great-grandfather, fought, in, World, War, II, ,, and, his, stories, about, the, war, have, been, passed, down, through, the, generations, of, our, family, .]              |[O, O, O, O, B-MISC, I-MISC, I-MISC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]|[World War II]                |[World, War, II]               |\n",
            "|[When, I, was, in, college, ,, I, spent, a, semester, studying, abroad, in, China, ,, and, it, was, an, eye-opening, experience, .]                                              |[O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O]                    |[China]                       |[China]                        |\n",
            "|[My, best, friend, and, I, have, been, planning, a, trip, to, South, America, for, years, ,, and, we're, finally, going, to, make, it, happen, this, summer, .]                  |[O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O] |[South America]               |[South, America]               |\n",
            "|[My, parents, own, a, small, motel, in, a, charming, seaside, town, ,, and, they've, been, running, it, for, over, 20, years, .]                                                 |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                        |[]                            |[]                             |\n",
            "|[Johnson, and, I, decided, to, take, a, road, trip, across, the, United, States, during, the, summer, after, we, graduated, from, college, .]                                    |[B-PER, O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC, O, O, O, O, O, O, O, O, O]            |[Johnson, United States]      |[Johnson, United, States]      |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+------------------------------+-------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['Peter Parker bookad a ticket for the concert. Ticket price is 100$ dollars']\n",
        "data_set = spark.createDataFrame(text, StringType()).toDF(\"text\")\n",
        "data_set.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8Yocs61ggUn",
        "outputId": "63304c9b-0ae7-4829-f5b6-39736188e158"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------+\n",
            "|text                                                                      |\n",
            "+--------------------------------------------------------------------------+\n",
            "|Peter Parker bookad a ticket for the concert. Ticket price is 100$ dollars|\n",
            "+--------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documenter = DocumentAssembler()\\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "token_classifier = RoBertaForTokenClassification.pretrained(\"roberta_base_token_classifier_ontonotes\", \"en\")\\\n",
        "    .setInputCols(['document', 'token'])\\\n",
        "    .setOutputCol('ner')\\\n",
        "    .setCaseSensitive(True)\\\n",
        "    .setMaxSentenceLength(512)\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "    .setInputCols(['document', 'token', 'ner'])\\\n",
        "    .setOutputCol('entities')\n",
        "\n",
        "chunk_tokenizer = ChunkTokenizer() \\\n",
        "    .setInputCols([\"entities\"]) \\\n",
        "    .setOutputCol(\"chunk_token\")\\\n",
        "    .setInfixPatterns([\"(\\b\\d{3}\\b)\"])\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    documenter,\n",
        "    tokenizer,\n",
        "    token_classifier,\n",
        "    ner_converter,\n",
        "    chunk_tokenizer\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsdnaGjSm7dx",
        "outputId": "7706b9df-96bc-438c-c5e6-a81861232a03"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta_base_token_classifier_ontonotes download started this may take some time.\n",
            "Approximate size to download 434.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(data_set).transform(data_set)\n",
        "model.selectExpr(\"ner.result as ner\", \"entities.result as entities\", \"chunk_token.result as chunk_token\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mjy0RMbq2gR",
        "outputId": "7a9805f7-7fee-49be-afeb-542cb4facedc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------+--------+-----------+\n",
            "|ner                                              |entities|chunk_token|\n",
            "+-------------------------------------------------+--------+-----------+\n",
            "|[B-PERSON, O, O, O, O, O, O, O, O, O, O, O, O, O]|[Peter] |[Peter]    |\n",
            "+-------------------------------------------------+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Defining exceptions\n",
        "exceptions= \"\"\"Peter Parker\n",
        "James Murphy\n",
        "Lucas Nelson\n",
        "\"\"\"\n",
        "\n",
        "#open text file\n",
        "text_file = open(\"exceptions.txt\", \"w\")\n",
        "\n",
        "#write string to file\n",
        "text_file.write(exceptions)\n",
        "\n",
        "#close file\n",
        "text_file.close()"
      ],
      "metadata": {
        "id": "rJu8IQ5qnSxQ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chunk_tokenizer= ChunkTokenizer() \\\n",
        "     .setInputCols([\"entities\"]) \\\n",
        "     .setOutputCol(\"chunk_token\") \\\n",
        "     .setExceptionsPath('exceptions.txt') \\\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    documenter,\n",
        "    tokenizer,\n",
        "    token_classifier,\n",
        "    ner_converter,\n",
        "    chunk_tokenizer\n",
        "])\n",
        "\n",
        "text = ['Peter Parker bookad a ticket for the concert. Ticket price is 100$ dollars']\n",
        "data_set = spark.createDataFrame(text, StringType()).toDF(\"text\")\n",
        "\n",
        "\n",
        "result = pipeline.fit(data_set).transform(data_set)\n",
        "result.selectExpr(\"entities.result as ner_chunk\" , \"chunk_token.result as chunk_token\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeBzyXHWtlJ4",
        "outputId": "3e26418c-9d18-4644-9b85-5bafabbba97a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|ner_chunk|chunk_token|\n",
            "+---------+-----------+\n",
            "|[Peter]  |[Peter]    |\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f7G2_CK-tx7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}