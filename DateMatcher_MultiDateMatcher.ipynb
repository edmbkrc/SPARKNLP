{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL7lSyDL1kzy",
        "outputId": "ec38f9ca-0b47-4ae5-9f51-bae11c1e99fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m579.5/579.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pyspark spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "from sparknlp.annotator import DocumentAssembler, DateMatcher, MultiDateMatcher\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "spark = sparknlp.start()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "u7LuIiVI1uYF",
        "outputId": "6c0550d0-e092-48e6-d62a-b73bc2d9d56d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7944e2d7e0e0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ec5b13b650d7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing DateMatcher and MultiDateMatcher"
      ],
      "metadata": {
        "id": "ttGLD0_G49U8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        ".setInputCol(\"text\") \\\n",
        ".setOutputCol(\"document\")\n",
        "\n",
        "date = DateMatcher() \\\n",
        ".setInputCols(\"document\") \\\n",
        ".setOutputCol(\"date\") \\\n",
        ".setOutputFormat(\"yyyy/MM/dd\")\n",
        "\n",
        "multiDate = MultiDateMatcher() \\\n",
        ".setInputCols(\"document\") \\\n",
        ".setOutputCol(\"multi_date\") \\\n",
        ".setOutputFormat(\"MM/dd/yy\")\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "    documentAssembler,\n",
        "    date,\n",
        "    multiDate\n",
        "])\n",
        "\n",
        "text_list = [\"See you on next monday.\",  \"She was born on 02/03/1966.\", \"The project started yesterday and will finish next year.\",\n",
        "             \"She will graduate by July 2023.\", \"She will visit doctor tomorrow and next month again.\"]\n",
        "\n",
        "\n",
        "spark_df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4z4w1CdD4aJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipeline.fit(spark_df).transform(spark_df)\n",
        "result.selectExpr(\"text\", \"date.result as date\", \"multi_date.result as multi_date\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkHDn7DH6cXs",
        "outputId": "7b00ed13-ec95-4128-ccba-e5a3aff65ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+------------+--------------------+\n",
            "|text                                                    |date        |multi_date          |\n",
            "+--------------------------------------------------------+------------+--------------------+\n",
            "|See you on next monday.                                 |[2024/09/23]|[09/23/24]          |\n",
            "|She was born on 02/03/1966.                             |[1966/02/03]|[02/03/66]          |\n",
            "|The project started yesterday and will finish next year.|[2025/09/16]|[09/16/25, 09/15/24]|\n",
            "|She will graduate by July 2023.                         |[2023/07/01]|[07/01/23]          |\n",
            "|She will visit doctor tomorrow and next month again.    |[2024/10/16]|[10/16/24, 09/17/24]|\n",
            "+--------------------------------------------------------+------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipeline.fit(spark_df).transform(spark_df)\n",
        "result.selectExpr(\"text\", \"date.result\", \"multi_date.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKtRvFoE7r8B",
        "outputId": "43d98bd1-d59e-4528-8b00-5d9858eb4274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+------------+--------------------+\n",
            "|text                                                    |result      |result              |\n",
            "+--------------------------------------------------------+------------+--------------------+\n",
            "|See you on next monday.                                 |[2024/09/23]|[09/23/24]          |\n",
            "|She was born on 02/03/1966.                             |[1966/02/03]|[02/03/66]          |\n",
            "|The project started yesterday and will finish next year.|[2025/09/16]|[09/16/25, 09/15/24]|\n",
            "|She will graduate by July 2023.                         |[2023/07/01]|[07/01/23]          |\n",
            "|She will visit doctor tomorrow and next month again.    |[2024/10/16]|[10/16/24, 09/17/24]|\n",
            "+--------------------------------------------------------+------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"date\", \"multi_date\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7R8PCI47_kI",
        "outputId": "539bb63e-98de-4c8b-952e-a7086bf29527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------+----------------------------------------------------------------------------------------------+\n",
            "|date                                             |multi_date                                                                                    |\n",
            "+-------------------------------------------------+----------------------------------------------------------------------------------------------+\n",
            "|[{date, 11, 18, 2024/09/23, {sentence -> 0}, []}]|[{date, 11, 18, 09/23/24, {sentence -> 0}, []}]                                               |\n",
            "|[{date, 16, 25, 1966/02/03, {sentence -> 0}, []}]|[{date, 16, 25, 02/03/66, {sentence -> 0}, []}]                                               |\n",
            "|[{date, 46, 54, 2025/09/16, {sentence -> 0}, []}]|[{date, 46, 54, 09/16/25, {sentence -> 0}, []}, {date, 20, 28, 09/15/24, {sentence -> 0}, []}]|\n",
            "|[{date, 21, 29, 2023/07/01, {sentence -> 0}, []}]|[{date, 21, 29, 07/01/23, {sentence -> 0}, []}]                                               |\n",
            "|[{date, 35, 44, 2024/10/16, {sentence -> 0}, []}]|[{date, 35, 44, 10/16/24, {sentence -> 0}, []}, {date, 22, 29, 09/17/24, {sentence -> 0}, []}]|\n",
            "+-------------------------------------------------+----------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relative Dates"
      ],
      "metadata": {
        "id": "g7iPjQhc8pNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DateMatcher and MultiDateMatcher annotators return relative dates as actual dates. But in this situation, we need to provide a reference point for the date. To accomplish this, an anchor date should be set, so the actual date can be calculated. These reference date parameters can be set by setAnchorDateDay(), setAnchorDateMonth(), setAnchorDateYear().\n",
        "\n",
        "If an anchor date parameter is not set, the current day or current month or current year will be set as the default value."
      ],
      "metadata": {
        "id": "8kSOF9_k83Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        ".setInputCol(\"text\") \\\n",
        ".setOutputCol(\"document\")\n",
        "\n",
        "multiDate = MultiDateMatcher() \\\n",
        "    .setInputCols(\"document\") \\\n",
        "    .setOutputCol(\"multi_date\") \\\n",
        "    .setOutputFormat(\"MM/dd/yyyy\")\\\n",
        "    .setAnchorDateYear(2005)\\\n",
        "    .setAnchorDateMonth(1)\\\n",
        "    .setAnchorDateDay(13)\\\n",
        "\n",
        "multiDate_no_day = MultiDateMatcher() \\\n",
        ".setInputCols(\"document\") \\\n",
        ".setOutputCol(\"multi_date_no_day\") \\\n",
        ".setOutputFormat(\"MM/dd/yyyy\") \\\n",
        ".setAnchorDateYear(2005) \\\n",
        ".setAnchorDateMonth(1) \\\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "    documentAssembler,\n",
        "    multiDate,\n",
        "    multiDate_no_day])\n",
        "\n",
        "\n",
        "text_list = [\"See you on next monday.\",  \"She was born on 02/03/1966.\", \"The project started on yesterday and will finish next year.\",\n",
        "             \"She will graduate by July 2023.\", \"She will visit doctor tomorrow and next month again.\"]\n",
        "\n",
        "spark_df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")"
      ],
      "metadata": {
        "id": "EGgjSh_c8cre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipeline.fit(spark_df).transform(spark_df)\n",
        "result.selectExpr(\"text\", \"multi_date.result as multi_date\", \"multi_date_no_day.result as multi_date_no_day\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkckvO7md1ox",
        "outputId": "a89d2712-da92-4bfd-9f1e-bf04e9ae5872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------+------------------------+------------------------+\n",
            "|text                                                       |multi_date              |multi_date_no_day       |\n",
            "+-----------------------------------------------------------+------------------------+------------------------+\n",
            "|See you on next monday.                                    |[01/17/2005]            |[01/17/2005]            |\n",
            "|She was born on 02/03/1966.                                |[02/03/1966]            |[02/03/1966]            |\n",
            "|The project started on yesterday and will finish next year.|[01/13/2006, 01/12/2005]|[01/16/2006, 01/15/2005]|\n",
            "|She will graduate by July 2023.                            |[07/01/2023]            |[07/01/2023]            |\n",
            "|She will visit doctor tomorrow and next month again.       |[02/13/2005, 01/14/2005]|[02/16/2005, 01/17/2005]|\n",
            "+-----------------------------------------------------------+------------------------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Date Formats"
      ],
      "metadata": {
        "id": "J2G5F-8Dg6qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "multiDate_1 = MultiDateMatcher() \\\n",
        "    .setInputCols(\"document\") \\\n",
        "    .setOutputCol(\"multi_date_1\") \\\n",
        "    .setOutputFormat(\"MM/dd/yy\")\n",
        "\n",
        "multiDate_2 = MultiDateMatcher() \\\n",
        "    .setInputCols(\"document\") \\\n",
        "    .setOutputCol(\"multi_date_2\") \\\n",
        "    .setOutputFormat(\"MMMM dd, yyyy\")\n",
        "\n",
        "\n",
        "multiDate_3 = MultiDateMatcher() \\\n",
        "    .setInputCols(\"document\") \\\n",
        "    .setOutputCol(\"multi_date_3\") \\\n",
        "    .setInputFormats([\"dd/MM/yyyy\"]) \\\n",
        "    .setOutputFormat(\", EEEEMM/dd/yyyy\")\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "  documentAssembler,\n",
        "  multiDate_1,\n",
        "  multiDate_2,\n",
        "  multiDate_3\n",
        "])\n",
        "\n",
        "text_list = [\"See you on 1st December 2004.\",  \"She was born on 02/03/1966.\", \"The project started on yesterday and will finish next year.\",\n",
        "             \"She will graduate by July 2023.\", \"She will visit doctor tomorrow and next month again.\"]\n",
        "\n",
        "spark_df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")"
      ],
      "metadata": {
        "id": "4SqJlTYoern0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipeline.fit(spark_df).transform(spark_df)\n",
        "result.selectExpr(\"text\", \"multi_date_1.result as multi_date_1\", \"multi_date_2.result as multi_date_2\", \"multi_date_3.result as multi_date_3\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv1jpsq8iMdO",
        "outputId": "a19cfe9f-4bc8-4aea-8fec-be64d9fd2f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------+--------------------+----------------------------------------+-----------------------+\n",
            "|text                                                       |multi_date_1        |multi_date_2                            |multi_date_3           |\n",
            "+-----------------------------------------------------------+--------------------+----------------------------------------+-----------------------+\n",
            "|See you on 1st December 2004.                              |[12/01/04]          |[December 01, 2004]                     |[]                     |\n",
            "|She was born on 02/03/1966.                                |[02/03/66]          |[February 03, 1966]                     |[, Wednesday03/02/1966]|\n",
            "|The project started on yesterday and will finish next year.|[09/16/25, 09/15/24]|[September 16, 2025, September 15, 2024]|[]                     |\n",
            "|She will graduate by July 2023.                            |[07/01/23]          |[July 01, 2023]                         |[]                     |\n",
            "|She will visit doctor tomorrow and next month again.       |[10/16/24, 09/17/24]|[October 16, 2024, September 17, 2024]  |[]                     |\n",
            "+-----------------------------------------------------------+--------------------+----------------------------------------+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing Days"
      ],
      "metadata": {
        "id": "gvGsCuRwi45u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes in a date expression, days are not specified. For example \"She will graduate by July 2023\". In this situation one can set a default day value for missing days using setDefaultDayWhenMissing. If it is not set, default value is 1."
      ],
      "metadata": {
        "id": "raFQP7-3jB1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "multiDate = MultiDateMatcher() \\\n",
        "    .setInputCols(\"document\") \\\n",
        "    .setOutputCol(\"date\")\n",
        "\n",
        "multiDate_missing_day_set = MultiDateMatcher() \\\n",
        "    .setInputCols(\"document\") \\\n",
        "    .setOutputCol(\"date_missing_day_set\") \\\n",
        "    .setDefaultDayWhenMissing(15)\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "    documentAssembler,\n",
        "    multiDate,\n",
        "    multiDate_missing_day_set\n",
        "])\n",
        "\n",
        "text_list = [\"See you on 1st December 2004.\",  \"She was born on 02/03/1966.\", \"The project started on yesterday and will finish next year.\",\n",
        "             \"She will graduate by July 2023.\", \"She will visit doctor tomorrow and next month again.\"]\n",
        "\n",
        "spark_df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(spark_df).transform(spark_df)\n",
        "result.selectExpr(\"text\", \"date.result as date\", \"date_missing_day_set.result as date_missing_day_set\").show(truncate=False)"
      ],
      "metadata": {
        "id": "FCTsvwdDigSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9914834-e79e-4c3c-fc5b-06ab52b34318"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------+------------------------+------------------------+\n",
            "|text                                                       |date                    |date_missing_day_set    |\n",
            "+-----------------------------------------------------------+------------------------+------------------------+\n",
            "|See you on 1st December 2004.                              |[2004/12/01]            |[2004/12/01]            |\n",
            "|She was born on 02/03/1966.                                |[1966/02/03]            |[1966/02/03]            |\n",
            "|The project started on yesterday and will finish next year.|[2025/09/17, 2024/09/16]|[2025/09/17, 2024/09/16]|\n",
            "|She will graduate by July 2023.                            |[2023/07/01]            |[2023/07/15]            |\n",
            "|She will visit doctor tomorrow and next month again.       |[2024/10/17, 2024/09/18]|[2024/10/17, 2024/09/18]|\n",
            "+-----------------------------------------------------------+------------------------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Languages\n",
        "Date matchers can be used with other languages. Its default value is \"en\"-English."
      ],
      "metadata": {
        "id": "7PSLYRjr8wp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "multiDate = MultiDateMatcher() \\\n",
        "    .setInputCols(\"document\") \\\n",
        "    .setOutputCol(\"multi_date\") \\\n",
        "    .setOutputFormat(\"yyyy/MM/dd\") \\\n",
        "    .setSourceLanguage(\"de\")\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "    documentAssembler,\n",
        "    multiDate\n",
        "])\n",
        "\n",
        "spark_df = spark.createDataFrame([[\"Das letzte zahlungsdatum dieser rechnung ist der 4. mai 1998.\"], [\"Wir haben morgen eine prüfung.\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(spark_df).transform(spark_df)\n",
        "result.selectExpr(\"text\", \"multi_date.result as date\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu--diQe77kJ",
        "outputId": "13791f74-0ac5-4390-9b17-dc7ad8e4c746"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------+------------+\n",
            "|text                                                         |date        |\n",
            "+-------------------------------------------------------------+------------+\n",
            "|Das letzte zahlungsdatum dieser rechnung ist der 4. mai 1998.|[1998/05/04]|\n",
            "|Wir haben morgen eine prüfung.                               |[2024/09/18]|\n",
            "+-------------------------------------------------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date matchers can extract dates from other languages. In the above German example, the first row contains an actual date while the second one has a relative date (morgen means tomorrow in English). They are formatted in the desired output format."
      ],
      "metadata": {
        "id": "vWeQVqA-83Np"
      }
    }
  ]
}